import torch
import gradio as gr
from diffusers import StableDiffusionPipeline
from transformers import AutoTokenizer, AutoModelForCausalLM
from datetime import datetime
from functools import lru_cache
import asyncio
import re
import requests
import hashlib
import random

# æ¨¡å‹åŠ è½½
class AIGCGenerator:
    def __init__(self):
        # åŠ è½½Qwenè¯­è¨€æ¨¡å‹çš„Tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            "Qwen/Qwen-1_8B-Chat",
            trust_remote_code=True,
            use_fast=False
        )
        # åŠ è½½Qwenè¯­è¨€æ¨¡å‹
        self.text_model = AutoModelForCausalLM.from_pretrained(
            "Qwen/Qwen-1_8B-Chat",
            device_map="auto",
            torch_dtype=torch.float16,
            trust_remote_code=True
        )
        # è®¾ç½®chatæ¨¡æ¿ï¼Œæ ¼å¼åŒ–è¾“å…¥ç”¨
        self.tokenizer.chat_template = """
        {% for message in messages %}
        {% if message['role'] == 'system' %}<|im_start|>system\n{{ message['content'] }}<|im_end|>
        {% elif message['role'] == 'user' %}<|im_start|>user\n{{ message['content'] }}<|im_end|>
        {% else %}<|im_start|>assistant\n{{ message['content'] }}<|im_end|>
        {% endif %}
        {% endfor %}
        <|im_start|>assistant\n"""

        # åŠ è½½Stable Diffusionå›¾åƒç”Ÿæˆæ¨¡å‹
        self.sd_pipe = StableDiffusionPipeline.from_pretrained(
            "stabilityai/stable-diffusion-2-1",
            torch_dtype=torch.float16,
            variant="fp16"
        ).to("cuda")
        self._optimize_pipeline()

    def _optimize_pipeline(self):
        # å›¾åƒç”Ÿæˆå†…å­˜ä¼˜åŒ–
        self.sd_pipe.enable_attention_slicing()
        self.sd_pipe.enable_model_cpu_offload()
        self.sd_pipe.enable_xformers_memory_efficient_attention()
        torch.cuda.empty_cache()



# ç”Ÿæˆæ¨¡å—
class ContentGenerator(AIGCGenerator):
    # å„ç§é£æ ¼çš„Promptæ¨¡æ¿é…ç½®
    PROMPT_CONFIG = {
        "å°çº¢ä¹¦é£æ ¼": {
            "system": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¾å¦†åšä¸»ï¼Œè¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”ŸæˆåŸåˆ›æ–‡æ¡ˆï¼ˆç¦æ­¢é‡å¤ç¤ºä¾‹ï¼‰ï¼š
ğŸ”¥ã€ç—›ç‚¹æ ‡é¢˜ã€‘ (1ä¸ªemoji+4-6å­—)
ğŸ‘‰ é—®é¢˜åœºæ™¯ï¼šæè¿°å…·ä½“ä½¿ç”¨åœºæ™¯å’Œé—®é¢˜
âœ… è§£å†³æ–¹æ¡ˆï¼šç”¨â—ï¸æ ‡è®°3ä¸ªæ ¸å¿ƒå–ç‚¹
ğŸŒŸ ä½¿ç”¨æ•ˆæœï¼šä½¿ç”¨å‰åå¯¹æ¯”
ğŸ·ï¸ æ ‡ç­¾ï¼š3-5ä¸ªç›¸å…³æ ‡ç­¾""",
            "example_input": "é®ç‘•è†",
            "example_output": """
ğŸ”¥ ç†¬å¤œæ•‘æ˜Ÿï¼
ğŸ‘‰ æ¯å¤©åŠ ç­åˆ°å‡Œæ™¨ï¼Œé»‘çœ¼åœˆé‡åˆ°ç²‰åº•éƒ½ç›–ä¸ä½...
âœ… ä¸‰å¤§ä¼˜åŠ¿ï¼š
â—ï¸ ä¸‰è‰²åˆ†åŒºé®ç‘•
â—ï¸ æ°´æ¶¦ä¸å¡ç²‰
â—ï¸ æŒå¦†12å°æ—¶
ğŸŒŸ è–„æ¶‚ä¸€å±‚å°±èƒ½ä¼ªè£…å¥½æ°”è‰²
ğŸ·ï¸ #é®ç‘•æ¨è #ç¾å¦†ç¥å™¨ #æ‰“å·¥äººå¿…å¤‡"""
        },

        "insé£æ ¼": {
        "system": """ä½ æ˜¯æœ‰ç™¾ä¸‡ç²‰ä¸çš„INSåšä¸»ï¼Œè¯·æŒ‰ä»¥ä¸‹ç»“æ„ä½¿ç”¨è½»æ¾é£æ ¼ç”ŸæˆåŸåˆ›æ–‡æ¡ˆï¼ˆç¦æ­¢é‡å¤ç¤ºä¾‹ï¼‰ï¼š
ğŸŒ¿ã€LIFE HACKã€‘ (1ä¸ªæ°›å›´æ„Ÿemoji+3-5è‹±æ–‡è¯)
â˜• ç—›ç‚¹åœºæ™¯ï¼šç”¨ç”Ÿæ´»åŒ–åœºæ™¯åˆ¶é€ å…±é¸£
ğŸ›‹ï¸ è§£å†³æ–¹æ¡ˆï¼šç”¨ğŸªæ ‡è®°3ä¸ªè®¾è®¡äº®ç‚¹
ğŸ“¸ è§†è§‰å¯¹æ¯”ï¼šbefore-afterçš„æ„å¢ƒæè¿°
ğŸŒ æ ‡ç­¾ç»„åˆï¼š2ä¸ª#Lifestyle + 1ä¸ª#å“ç‰Œè°ƒæ€§""",
        "example_input": "é¦™è–°æœº",
        "example_output": """
ğŸŒ¿ Urban Oasis
â˜• åŠ ç­å›å®¶æ€»é—»åˆ°å¤–å–ç›’é…¸å‘³
ğŸ›‹ï¸ ç©ºé—´æ”¹é€ æœ¯ï¼š
ğŸª é›¾åŒ–ç²’å­ç»†è‡³0.3Î¼m
ğŸª æœˆå…‰æ³¢çº¹å…‰å½±
ğŸª è¯­éŸ³è°ƒèŠ‚æµ“åº¦
ğŸ“¸ ä»"åˆç§Ÿå±‹å¼‚å‘³"åˆ°"ç§äººSPAé¦†"
ğŸŒ #HomeDecor #WellnessLiving #MUJIvibes"""
        },

        "Bç«™é£æ ¼": {
        "system": """ä½ æ˜¯ä¼šæ•´æ´»çš„Bç«™UPä¸»ï¼Œè¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”Ÿæˆæœ‰è¶£åŸåˆ›æ–‡æ¡ˆï¼ˆç¦æ­¢é‡å¤ç¤ºä¾‹ï¼‰ï¼š
        ğŸ¶ã€ç¦»è°±ç—›ç‚¹ã€‘ (1ä¸ªé­”æ€§emoji+å£è¯­åŒ–çŸ­å¥)
        ğŸ¤¯ å´©æºƒå®å½•ï¼šå¤¸å¼ åŒ–æ¼”ç»çœŸå®çª˜å¢ƒ
        ğŸš¨ çœŸé¦™è­¦å‘Šï¼šç”¨âš¡æ ‡3ä¸ªé€†å¤©åŠŸèƒ½
        ğŸŒˆ æ•ˆæœæš´å‡»ï¼šå¯¹æ¯”æ®µå­+çƒ­æ¢—call back
        ğŸ® å¿…å¸¦æ¢—ï¼š#ç”µå­å® ç‰© + #è´«æ°‘çªŸXX""",
        "example_input": "ç”µåŠ¨ç‰™åˆ·",
        "example_output": """
        ğŸ¶ åˆ·ç‰™åˆ·å‡ºç«æ˜Ÿå­ï¼
        ğŸ¤¯ "è¿™éœ‡åŠ¨æ€•ä¸æ˜¯è£…äº†å°é©¬è¾¾"ï¼ˆå¼¹å¹•ï¼šç”µé’»è­¦å‘Šï¼ï¼‰
        ğŸš¨ é»‘ç§‘æŠ€ä¸‰è¿ï¼š
        âš¡ å‹åŠ›æ„Ÿåº”è‡ªåŠ¨é™é¢‘
        âš¡ èˆŒè‹”æ¸…æ´æ¨¡å¼
        âš¡ ç»­èˆªåŠæ‰“æŸæœ
        ğŸŒˆ ä»"ç‰™é¾ˆåˆºå®¢"åˆ°"å£è…”å¤§ä¿å¥"ï¼ˆå¼¹å¹•ï¼šç‰™åŒ»è¿å¤œæ”¹è¡Œï¼‰
        ğŸ® #æ‰“å·¥äººç”Ÿå­˜åŒ… #å®¿èˆè¿ç¦å“"""
        }
      }

    def __init__(self):
        super().__init__()
        # ç™¾åº¦ç¿»è¯‘APIçš„é…ç½®
        self.baidu_appid = "20250410002329355"  #id
        self.baidu_key = "p5GCT04rp8Il7mr62W6n" #å¯†é’¥

    @lru_cache(maxsize=50)
    def generate_text(self, keywords: str, style: str) -> str:
        # è·å–æ‰€é€‰é£æ ¼é…ç½®
        config = self.PROMPT_CONFIG[style]

        # æ„å»ºè¾“å…¥å¯¹è¯æ¶ˆæ¯åºåˆ—
        messages = [
            {"role": "system", "content": config["system"]},
            {"role": "user", "content": f"ç¤ºä¾‹äº§å“ï¼š{config['example_input']}"},
            {"role": "assistant", "content": config["example_output"]},
            {"role": "user", "content": f"æ–°äº§å“ï¼š{keywords}"},
            {"role": "user", "content": "è¯·ç”Ÿæˆå…¨æ–°å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ç¤ºä¾‹ä¸­çš„ä»»ä½•å…·ä½“æè¿°"}
        ]

        # è½¬ä¸ºæ¨¡å‹éœ€è¦çš„Promptæ ¼å¼
        formatted_prompt = self.tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        #print("æœ€ç»ˆç”¨äºç”Ÿæˆçš„ Promptï¼š", formatted_prompt)

        # ç¼–ç å¹¶ç”Ÿæˆå†…å®¹
        inputs = self.tokenizer(formatted_prompt, return_tensors="pt").to("cuda")
        outputs = self.text_model.generate(
            **inputs,
            max_new_tokens=1024,
            temperature=1.0,
            top_p=0.9,
            repetition_penalty=1.5,
            do_sample=True,
            num_beams=3,
            no_repeat_ngram_size=3,
            pad_token_id=self.tokenizer.eos_token_id
        )

        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        print("åŸå§‹è¾“å‡º >>>", full_text)

        return self._process_output(full_text, config["example_output"])


    def _process_output(self, text: str, example: str) -> str:
        # æ¸…æ´—æ¨¡å‹ç”Ÿæˆçš„åŸå§‹æ–‡æœ¬ï¼Œæå–æœ‰æ•ˆå†…å®¹
        split_markers = ["è¯·ç”Ÿæˆå…¨æ–°å†…å®¹",f"æ–°äº§å“ï¼š","<|im_start|>assistant"]

        for marker in split_markers:
            if marker in text:
                new_content = text.split(marker)[-1]
                break
        else:
            new_content = text

        # æ¸…ç†ç³»ç»Ÿæ ‡è®°å’Œç¤ºä¾‹å†…å®¹
        clean_text = re.sub(r"<\|.*?\|>|user|assistant|system", "", new_content)
        clean_text = clean_text.replace(example.split("ğŸ‘‰")[0], "").strip()

        lines = clean_text.split("\n")
        formatted_lines = []
        section_found = False

        # åŒ¹é…è¡Œé¦– emoji å­—ç¬¦ï¼šåŒ…æ‹¬è¡¨æƒ…ç¬¦å·åŒºã€éƒ¨åˆ† Unicode ç‰¹ç¬¦å·åŒº
        emoji_pattern = re.compile(r"^[\U0001F300-\U0001FAFF\u2600-\u26FF\u2700-\u27BF]")

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æ£€æµ‹ä»¥ emoji å¼€å¤´çš„æ®µè½ï¼Œæ¢è¡Œç¾åŒ–æ˜¾ç¤º
            if emoji_pattern.match(line):
                formatted_lines.append(f"\n{line}")
                section_found = True
            elif section_found:
                formatted_lines.append(line)

        return "\n".join(formatted_lines).strip()[:1000]

    async def generate_image(self, keywords: str, style: str):
        # æ„é€ ä¸­æ–‡promptç”¨äºå›¾åƒ
        prompt_cn = f"{keywords} äº§å“ç…§ç‰‡ï¼Œ{style}é£æ ¼ï¼Œé«˜è´¨é‡ï¼Œé«˜æ¸…"
        prompt_en = self._translate_to_en(prompt_cn)

        # å›¾åƒç”Ÿæˆ
        return self.sd_pipe(
            prompt=prompt_en,
            negative_prompt="text, watermark, low quality",
            width=768,
            height=512,
            num_inference_steps=30,
            guidance_scale=7.5
        ).images[0]

    def _translate_to_en(self, text):
        # è°ƒç”¨ç™¾åº¦ç¿»è¯‘æ¥å£
        salt = str(random.randint(32768, 65536))
        sign = hashlib.md5((self.baidu_appid + text + salt + self.baidu_key).encode()).hexdigest()
        url = "http://api.fanyi.baidu.com/api/trans/vip/translate"
        params = {
            "q": text,
            "from": "zh",
            "to": "en",
            "appid": self.baidu_appid,
            "salt": salt,
            "sign": sign
        }
        try:
            res = requests.get(url, params=params, timeout=5)
            result = res.json()
            if "trans_result" in result:
                return result["trans_result"][0]["dst"]
            else:
                print("ç¿»è¯‘å¤±è´¥ï¼š", result)
                return "high quality product photo"
        except Exception as e:
            print("ç¿»è¯‘æ¥å£å¼‚å¸¸ï¼š", e)
            return "high quality product photo"


# Gradio ç•Œé¢æ„å»ºç±»
class AIGCApp:
    def __init__(self):
        self.generator = ContentGenerator()

    def create_interface(self):
        with gr.Blocks(theme=gr.themes.Soft(), css=".output-text {font-size: 14px}") as demo:
            gr.Markdown("# ğŸ›ï¸ ç”µå•†æ–‡æ¡ˆç”Ÿæˆå™¨ ")

            with gr.Row():
                with gr.Column():
                    keywords = gr.Textbox(label="äº§å“åç§°", placeholder="è¾“å…¥å•†å“å…³é”®è¯ï¼ˆå¦‚ï¼šçç é¡¹é“¾ï¼‰")
                    style_selector = gr.Dropdown(
                        list(ContentGenerator.PROMPT_CONFIG.keys()),
                        label="å†…å®¹é£æ ¼",
                        value="å°çº¢ä¹¦é£æ ¼"
                    )
                    generate_btn = gr.Button("ç«‹å³ç”Ÿæˆ", variant="primary")
                    gr.Examples(examples=[["æ°”å«ç²‰æ‰‘"], ["å¤´æˆ´è€³æœº"]], inputs=[keywords])

                with gr.Column():
                    text_output = gr.Textbox(label="ç”Ÿæˆæ–‡æ¡ˆ", lines=10, elem_classes=["output-text"])
                    image_output = gr.Image(label="äº§å“é…å›¾", height=400)

            generate_btn.click(self._disable_btn, None, generate_btn).then(
                self._generate_content,
                inputs=[keywords, style_selector],
                outputs=[text_output, image_output]
            ).then(self._enable_btn, None, generate_btn)

            return demo

    async def _generate_content(self, keywords, style):
        # å¹¶è¡Œç”Ÿæˆæ–‡æ¡ˆå’Œå›¾ç‰‡
        text = await asyncio.to_thread(self.generator.generate_text, keywords, style)
        image = await self.generator.generate_image(keywords, style)
        return text, image

    def _disable_btn(self):
        return gr.update(interactive=False)

    def _enable_btn(self):
        return gr.update(interactive=True)





if __name__ == "__main__":
    app = AIGCApp().create_interface()
    app.queue().launch(
        debug=True,
        share=True
    )